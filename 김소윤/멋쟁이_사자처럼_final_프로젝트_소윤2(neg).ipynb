{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------"
      ],
      "metadata": {
        "id": "37NcAZgkOQ4n"
      },
      "id": "37NcAZgkOQ4n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì¶”ê°€ ë¼ë²¨ë§ ì‹œì´ì‘"
      ],
      "metadata": {
        "id": "yayrd0yZ7EDr"
      },
      "id": "yayrd0yZ7EDr"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as numpy"
      ],
      "metadata": {
        "id": "HEZo5JAPORkY"
      },
      "id": "HEZo5JAPORkY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attraction: museum, park,view,beautiful,amazing\n",
        "#eat:restaurant, bar\n",
        "#transport: great,train, subway,metro, bus,station,metre,underground, transport, access, location, centre, position,tube\n",
        "#service: lovely, friendly, staff, helpful,balcony, room, breakfast, tidy, polite, reception"
      ],
      "metadata": {
        "id": "CGCUvXrmOToY"
      },
      "id": "CGCUvXrmOToY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception']\n",
        "\n",
        "roomsize_keywords = ['tidy, narrows, narrow, compact, small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']"
      ],
      "metadata": {
        "id": "kyzX1qkTOVhI"
      },
      "id": "kyzX1qkTOVhI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------"
      ],
      "metadata": {
        "id": "CzEeY2OvogK3"
      },
      "id": "CzEeY2OvogK3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# noun_adj_pairs_raw(neg) íŒŒì¼ ë¨¼ì € ì´ìš©!"
      ],
      "metadata": {
        "id": "zWBnKfUlomto"
      },
      "id": "zWBnKfUlomto"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "df = pd.read_csv('/content/noun_adj_pairs_raw(neg).csv')\n",
        "\n",
        "print(\"ì›ë³¸ ë°ì´í„°\")\n",
        "print(df)\n",
        "print(\"---\")\n",
        "\n",
        "# ì •ì›ë‹˜ì´ ë§Œë“  í‚¤ì›Œë“œ ë”•ì…”ë„ˆë¦¬\n",
        "keywords_dict = {\n",
        "    'attraction': ['museum', 'park', 'view', 'beautiful', 'amazing'],\n",
        "    'eat': ['restaurant', 'bar'],\n",
        "    'transport': ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube'],\n",
        "    'service': ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception'],\n",
        "    'roomsize': ['tiny', 'narrows', 'narrow', 'compact', 'small'],\n",
        "    'noisy': ['noise', 'noisy', 'soundproofng', 'soundproof', 'sound', 'sounds'],\n",
        "    'dirty': ['dirty', 'uncleaned', 'cleaned', 'toilet', 'bathroom', 'pillow', 'bug', 'smell'],\n",
        "    'expensive': ['expensive', 'price', 'pricy', 'high', 'prices', 'payment']\n",
        "}\n",
        "\n",
        "# ë¼ë²¨ë§ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ë³´ì!\n",
        "def assign_label(text):\n",
        "    if pd.isna(text): # í˜¹ì‹œ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° (NaN)ë¥¼ ëŒ€ë¹„\n",
        "        return 'Not Applicable'\n",
        "    text = str(text).lower() # ëŒ€ì†Œë¬¸ì ìƒê´€ì—†ì´ ì°¾ìœ¼ë ¤ë©´ ì†Œë¬¸ìë¡œ ë‹¤ ë°”ê¿”ì£¼ê¸°. ë° ë¬¸ìì—´!\n",
        "\n",
        "    for label, keywords in keywords_dict.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                    return label # í‚¤ì›Œë“œë¥¼ ì°¾ìœ¼ë©´ í•´ë‹¹ ë¼ë²¨ì„ ë°˜í™˜í•˜ê³  ë!\n",
        "    return 'Other/General' # í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ë„ ëª» ì°¾ìœ¼ë©´ 'Other/General'í‚¤ì›Œë“œ\n",
        "\n",
        "\n",
        "# í˜•ìš©ì‚¬ì™€ ëª…ì‚¬ë¥¼ ë„ì–´ì“°ê¸°ë¡œ ì—°ê²°í•´ì„œ í•˜ë‚˜ì˜ ë¬¸ì¥ì²˜ëŸ¼ ë§Œë“¤ê¸°\n",
        "df['combined_text'] = df['adj'].astype(str) + ' ' + df['noun'].astype(str)\n",
        "\n",
        "# ìƒˆë¡œìš´ 'label' ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ í•¨ìˆ˜ë¥¼ ì ìš©\n",
        "df['label'] = df['combined_text'].apply(assign_label)\n",
        "\n",
        "print(df[['adj', 'noun', 'combined_text', 'label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnLofHglOXzI",
        "outputId": "a95b551d-b8bb-4a72-c680-9cd93bbcb459"
      },
      "id": "NnLofHglOXzI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›ë³¸ ë°ì´í„°\n",
            "             adj     noun\n",
            "0       possible     site\n",
            "1          small     room\n",
            "2            big   window\n",
            "3           high  ceiling\n",
            "4           mini   fridge\n",
            "...          ...      ...\n",
            "285664      free  parking\n",
            "285665    public   garage\n",
            "285666       hot     week\n",
            "285667      more      air\n",
            "285668       hot      air\n",
            "\n",
            "[285669 rows x 2 columns]\n",
            "---\n",
            "             adj     noun  combined_text          label\n",
            "0       possible     site  possible site  Other/General\n",
            "1          small     room     small room        service\n",
            "2            big   window     big window  Other/General\n",
            "3           high  ceiling   high ceiling      expensive\n",
            "4           mini   fridge    mini fridge  Other/General\n",
            "...          ...      ...            ...            ...\n",
            "285664      free  parking   free parking     attraction\n",
            "285665    public   garage  public garage  Other/General\n",
            "285666       hot     week       hot week  Other/General\n",
            "285667      more      air       more air  Other/General\n",
            "285668       hot      air        hot air  Other/General\n",
            "\n",
            "[285669 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bert íŒŒì¼ ì´ìš©"
      ],
      "metadata": {
        "id": "thWZ0wPkszgV"
      },
      "id": "thWZ0wPkszgV"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# 1. ìˆ˜ë™ìœ¼ë¡œ ì •ì˜í•œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception']\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']\n",
        "\n",
        "# ëª¨ë“  ìˆ˜ë™ í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ì˜ ì„¸íŠ¸ë¡œ í†µí•©\n",
        "manual_keywords = set(attraction_keywords + eat_keywords + transport_keywords + service_keywords + roomsize_keywords + noisy_keywords + dirty_keywords + expensive_keywords)\n",
        "\n",
        "# 2. BERT ë¶€ì • ë¦¬ë·° ë¶„ì„ íŒŒì¼ ë¡œë“œ\n",
        "df_bert_neg  = pd.read_csv(\"/content/negative_reviews_analysis_1.csv\")\n",
        "\n",
        "# 3. BERT íŒŒì¼ì—ì„œ ëª¨ë“  ë‹¨ì–´ ì¶”ì¶œ\n",
        "all_words = []\n",
        "for pair_string in df_bert_neg['word_pair']:\n",
        "    try:\n",
        "        pair = eval(pair_string)\n",
        "        if isinstance(pair, tuple) and len(pair) == 2:\n",
        "            all_words.extend(pair)\n",
        "    except (SyntaxError, NameError):\n",
        "        continue\n",
        "\n",
        "# 4. ìˆ˜ë™ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ë‹¨ì–´(ìƒˆë¡œìš´ í‚¤ì›Œë“œ í›„ë³´) ì°¾ê¸°\n",
        "new_keywords_candidates = [word for word in all_words if word not in manual_keywords]\n",
        "\n",
        "# 5. ìƒˆë¡œìš´ í‚¤ì›Œë“œ í›„ë³´ì˜ ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ìƒìœ„ 20ê°œ ì¶œë ¥\n",
        "new_keyword_counts = Counter(new_keywords_candidates)\n",
        "\n",
        "print(\"\\n--- BERT ë¶„ì„ì—ì„œ ë°œê²¬ëœ ìƒˆë¡œìš´ í‚¤ì›Œë“œ í›„ë³´ (ìƒìœ„ 20ê°œ) ---\")\n",
        "for word, count in new_keyword_counts.most_common(20):\n",
        "    print(f\"  - {word}: {count:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "7rZ5s0p_r1Qc",
        "outputId": "8d4490df-7c26-49ed-c755-0afea80b3aa4"
      },
      "id": "7rZ5s0p_r1Qc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/negative_reviews_analysis_1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3112654589.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 2. BERT ë¶€ì • ë¦¬ë·° ë¶„ì„ íŒŒì¼ ë¡œë“œ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_bert_neg\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/negative_reviews_analysis_1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 3. BERT íŒŒì¼ì—ì„œ ëª¨ë“  ë‹¨ì–´ ì¶”ì¶œ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/negative_reviews_analysis_1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_pairì»¬ëŸ¼ ì‚¬ìš©í•´ì„œ, ë¹ˆë„ìˆ˜ ì°¾ì•„ë‚´ê¸°!"
      ],
      "metadata": {
        "id": "nmaRWJEv3nbL"
      },
      "id": "nmaRWJEv3nbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "import string\n",
        "\n",
        "# ë¶„ì„ ëŒ€ìƒ í˜•ìš©ì‚¬ ì •ì˜\n",
        "# ëª…ì‚¬ì— ëŒ€í•œ ê¾¸ë°ˆì— ì§‘ì¤‘í•  ë§Œí•œ í˜•ìš©ì‚¬ë“¤\n",
        "# 'bed', 'hotel', 'service' ë“±ì€ ëª…ì‚¬ì— ë” ê°€ê¹Œì›Œì„œ ì´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œì™¸\n",
        "target_adjectives = ['very', 'too', 'poor', 'good', 'bad', 'hot', 'old', 'cold', 'slow', 'other', 'more', 'much']\n",
        "\n",
        "# 'word_pair' ì»¬ëŸ¼ì—ì„œ í˜•ìš©ì‚¬ì™€ ëª…ì‚¬ ë¶„ë¦¬\n",
        "def parse_word_pair(pair_string):\n",
        "    try:\n",
        "        if pair_string.startswith('(') and pair_string.endswith(')'): #'string' ë¦¬í„°ëŸ´ì´ ì•„ë‹Œ ì‹¤ì œ íŒŒì´ì¬ íŠœí”Œ í˜•íƒœì¸ì§€ í™•ì¸\n",
        "            pair = eval(pair_string)\n",
        "            if isinstance(pair, tuple) and len(pair) == 2:\n",
        "                adj = str(pair[0]).strip() # íŠœí”Œ ìš”ì†Œì˜ íƒ€ì…ë„ í™•ì¸í•˜ì—¬ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°\n",
        "                noun = str(pair[1]).strip()\n",
        "                return (adj, noun)\n",
        "        return None\n",
        "    except (SyntaxError, NameError, TypeError): # TypeErrorë„ ì¶”ê°€í•´ì„œ ì¢€ ë” ê²¬ê³ í•˜ê²Œ!\n",
        "        return None\n",
        "\n",
        "df_bert_neg['word_pair_tuple'] = df_bert_neg['word_pair'].apply(parse_word_pair)\n",
        "df_bert_neg.dropna(subset=['word_pair_tuple'], inplace=True) # ìœ íš¨í•˜ì§€ ì•Šì€ ìŒ ì œê±°\n",
        "\n",
        "# í•´ë‹¹ íƒ€ê²Ÿ í˜•ìš©ì‚¬ê°€ í¬í•¨ëœ ìŒë§Œ í•„í„°ë§\n",
        "for target_adj in target_adjectives:\n",
        "    filtered_pairs = df_bert_neg[df_bert_neg['word_pair_tuple'].apply(lambda x: x[0] == target_adj)] # word_pair_tupleì€ (adj, noun) í˜•íƒœì˜ íŠœí”Œì´ë¯€ë¡œ, adjê°€ target_adjì™€ ê°™ì€ì§€ í™•ì¸\n",
        "\n",
        "    # í•´ë‹¹ í˜•ìš©ì‚¬ê°€ ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ë“¤ë§Œ ì¶”ì¶œ\n",
        "    nouns_for_adj = [pair[1] for pair in filtered_pairs['word_pair_tuple']]\n",
        "\n",
        "    if nouns_for_adj: # ëª…ì‚¬ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¶œë ¥\n",
        "        noun_counts_for_adj = Counter(nouns_for_adj).most_common(10)\n",
        "        print(f\"'{target_adj}'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ {len(nouns_for_adj):,}ê°œ) :\")\n",
        "        for noun, count in noun_counts_for_adj:\n",
        "            print(f\"  - {noun}: {count:,}\")\n",
        "        print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kxCKd7etgpI",
        "outputId": "2eaebf16-0856-49f3-8d19-7cc13ed06e1c"
      },
      "id": "4kxCKd7etgpI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'very'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 10,698ê°œ) :\n",
            "  - small: 1,298\n",
            "  - poor: 718\n",
            "  - noisy: 571\n",
            "  - expensive: 537\n",
            "  - slow: 348\n",
            "  - bad: 332\n",
            "  - good: 272\n",
            "  - hot: 266\n",
            "  - uncomfortable: 231\n",
            "  - old: 224\n",
            "--------------------------------------------------\n",
            "'too'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 3,664ê°œ) :\n",
            "  - small: 819\n",
            "  - expensive: 386\n",
            "  - hot: 302\n",
            "  - much: 224\n",
            "  - soft: 138\n",
            "  - high: 131\n",
            "  - warm: 96\n",
            "  - noisy: 96\n",
            "  - many: 91\n",
            "  - hard: 88\n",
            "--------------------------------------------------\n",
            "'poor'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 1,678ê°œ) :\n",
            "  - service: 150\n",
            "  - breakfast: 114\n",
            "  - quality: 93\n",
            "  - value: 69\n",
            "  - room: 60\n",
            "  - wifi: 54\n",
            "  - staff: 47\n",
            "  - selection: 35\n",
            "  - lighting: 35\n",
            "  - connection: 32\n",
            "--------------------------------------------------\n",
            "'good'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 1,160ê°œ) :\n",
            "  - value: 96\n",
            "  - hotel: 44\n",
            "  - sleep: 43\n",
            "  - service: 36\n",
            "  - room: 36\n",
            "  - thing: 29\n",
            "  - location: 27\n",
            "  - breakfast: 26\n",
            "  - experience: 26\n",
            "  - idea: 23\n",
            "--------------------------------------------------\n",
            "'bad'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 1,207ê°œ) :\n",
            "  - experience: 141\n",
            "  - smell: 110\n",
            "  - room: 57\n",
            "  - thing: 48\n",
            "  - hotel: 42\n",
            "  - service: 41\n",
            "  - sleep: 28\n",
            "  - wifi: 27\n",
            "  - breakfast: 25\n",
            "  - staff: 24\n",
            "--------------------------------------------------\n",
            "'hot'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 815ê°œ) :\n",
            "  - water: 238\n",
            "  - food: 54\n",
            "  - breakfast: 34\n",
            "  - room: 33\n",
            "  - day: 25\n",
            "  - drink: 23\n",
            "  - air: 23\n",
            "  - t: 20\n",
            "  - tub: 13\n",
            "  - shower: 12\n",
            "--------------------------------------------------\n",
            "'old'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 851ê°œ) :\n",
            "  - room: 60\n",
            "  - hotel: 51\n",
            "  - furniture: 48\n",
            "  - building: 34\n",
            "  - carpet: 26\n",
            "  - bathroom: 24\n",
            "  - bed: 22\n",
            "  - window: 20\n",
            "  - facility: 17\n",
            "  - mattress: 13\n",
            "--------------------------------------------------\n",
            "'cold'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 474ê°œ) :\n",
            "  - water: 50\n",
            "  - room: 35\n",
            "  - air: 33\n",
            "  - shower: 26\n",
            "  - breakfast: 17\n",
            "  - food: 17\n",
            "  - t: 12\n",
            "  - egg: 11\n",
            "  - drink: 10\n",
            "  - bathroom: 9\n",
            "--------------------------------------------------\n",
            "'slow'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 329ê°œ) :\n",
            "  - service: 63\n",
            "  - wifi: 33\n",
            "  - check: 26\n",
            "  - elevator: 21\n",
            "  - staff: 12\n",
            "  - room: 10\n",
            "  - connection: 10\n",
            "  - internet: 10\n",
            "  - lift: 8\n",
            "  - response: 5\n",
            "--------------------------------------------------\n",
            "'other'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 1,323ê°œ) :\n",
            "  - hotel: 220\n",
            "  - room: 186\n",
            "  - guest: 112\n",
            "  - side: 47\n",
            "  - people: 40\n",
            "  - thing: 31\n",
            "  - staff: 30\n",
            "  - option: 22\n",
            "  - place: 20\n",
            "  - hand: 14\n",
            "--------------------------------------------------\n",
            "'more'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 1,169ê°œ) :\n",
            "  - expensive: 47\n",
            "  - comfortable: 34\n",
            "  - space: 28\n",
            "  - staff: 24\n",
            "  - money: 22\n",
            "  - room: 20\n",
            "  - helpful: 19\n",
            "  - minute: 17\n",
            "  - hour: 17\n",
            "  - friendly: 16\n",
            "--------------------------------------------------\n",
            "'much'ì´(ê°€) ê¾¸ë©°ì£¼ëŠ” ëª…ì‚¬ (ì´ 774ê°œ) :\n",
            "  - well: 141\n",
            "  - noise: 54\n",
            "  - small: 53\n",
            "  - more: 33\n",
            "  - time: 25\n",
            "  - room: 25\n",
            "  - money: 19\n",
            "  - space: 17\n",
            "  - choice: 14\n",
            "  - sleep: 14\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ê°¯ìˆ˜ê°€ ì¢€ ì ë”ë¼ë„ ëª…ì‚¬ì— ì§‘ì¤‘!\n",
        "\n",
        "\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception', 'poor','slow','other','old','cold']\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell','bad']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment','more']\n",
        "\n",
        "\n",
        "\n",
        "- very í˜•ìš©ì‚¬ë¥¼ ê¾¸ë©°ì£¼ëŠ” ì—­í• ì´ ë„ˆë¬´ ê°•í•´ì„œ ì œì™¸\n",
        "- too í˜•ìš©ì‚¬ë¥¼ ê¾¸ë©°ì£¼ëŠ” ì—­í• ì´ ë„ˆë¬´ ê°•í•´ì„œ ì œì™¸\n",
        "- poor -> service/breakfast/quality -> service\n",
        "- good -> value/hotel/sleep -> ?\n",
        "- bad -> experience/smell/room -> dirty\n",
        "- hot -> water/food/breakfast -> ?\n",
        "- old -> room/hotel/furniture -> service\n",
        "- cold -> water/room/air -> service\n",
        "- slow -> service/wifi/check -> service\n",
        "- other -> hotel/room/guest -> service\n",
        "- more -> expensive/comfortable/space -> expensive\n",
        "- much í˜•ìš©ì‚¬ë¥¼ ê¾¸ë©°ì£¼ëŠ” ì—­í• ì´ ë„ˆë¬´ ê°•í•´ì„œ ì œì™¸"
      ],
      "metadata": {
        "id": "rzwQsVGn6ggE"
      },
      "id": "rzwQsVGn6ggE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ì¶”ê°€ì ì¸ ì˜ê²¬,,,!\n",
        "\n",
        "# \"ì‹œì„¤/ì–´ë©”ë‹ˆí‹°\" ê´€ë ¨ ëª…ì‚¬ë“¤ì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬ ê°•í™”\n",
        "facility_amenity_keywords = ['hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress', 'wifi', 'connection', 'elevator', 'lift', 'fridge', 'quality', 'value', 'lighting', 'tub', 'shower']\n",
        "\n",
        "# \"ê²½í—˜/ìƒí™©\" ê´€ë ¨ ëª…ì‚¬ ì¹´í…Œê³ ë¦¬ (ì¶”ìƒì ì¸ ê²ƒ í¬í•¨)\n",
        "experience_condition_keywords = ['experience', 'sleep', 'thing', 'day', 'smell', 'response', 'time', 'space']\n",
        "\n",
        "# \"ì‹ì‚¬/ìŒì‹\" ê´€ë ¨ ëª…ì‚¬ ì¹´í…Œê³ ë¦¬\n",
        "food_keywords = ['breakfast', 'food', 'drink', 'egg', 'selection']\n",
        "\n",
        "ì´ëŸ°ì‹ìœ¼ë¡œ ë” ë‚˜ëˆ„ëŠ”ê±°ë³´ë‹¤ëŠ” ì´ëŒ€ë¡œ ìœ ì§€í•˜ëŠ”ê²Œ ë‚«ê²Œì¬¬,,?!??!\n"
      ],
      "metadata": {
        "id": "A_nlMed_-Tmt"
      },
      "id": "A_nlMed_-Tmt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í”¼ë“œë°± ë°˜ì˜"
      ],
      "metadata": {
        "id": "ZEEYmdvVH_bY"
      },
      "id": "ZEEYmdvVH_bY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "facility_amenity_keywords = [\n",
        "    'hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress',\n",
        "    'wifi', 'connection', 'elevator', 'lift', 'fridge', 'lighting', 'tub', 'shower',\n",
        "    'air' # 'hot', 'cold'ê°€ ê¾¸ë¯¸ë˜ 'air' ì¶”ê°€\n",
        "]\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small'] # 'room'ì€ service_keywordsë¡œ ì´ë™\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds','sleep'] # 'sleep'ì¶”ê°€\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell', 'bad'] # 'bad'ë¥¼ ì²­ê²°ë„ì™€ ì—°ê´€\n",
        "service_keywords = [\n",
        "    'lovely', 'friendly', 'staff', 'helpful', 'polite', 'reception', 'service', # ê¸°ë³¸ì ì¸ ì„œë¹„ìŠ¤ ìš”ì†Œ\n",
        "    'balcony', 'room', 'breakfast', 'tidy', # 'room', 'balcony'ëŠ” ì‹œì„¤ì  ì„œë¹„ìŠ¤, 'breakfast', 'tidy'ëŠ” ì„œë¹„ìŠ¤ í’ˆì§ˆ ê´€ë ¨\n",
        "    'poor', 'slow', 'old', 'cold', 'more', # BERTì—ì„œ ë‚˜ì˜¨ í˜•ìš©ì‚¬/ë¶€ì‚¬ë“¤ì„ ì„œë¹„ìŠ¤ ë° í™˜ê²½ ìƒíƒœ í‰ê°€ ìš”ì†Œë¡œ í¬í•¨\n",
        "    'value', 'quality', 'check', 'experience', 'response', # poor, goodì´ ê¾¸ë¯¸ë˜ ì¶”ìƒì ì¸ ëª…ì‚¬ ì¤‘ ì„œë¹„ìŠ¤ì™€ ì—°ê´€\n",
        "    'food', 'drink', 'egg', 'selection' # ì‹ì‚¬/ìŒì‹ ê´€ë ¨ ëª…ì‚¬ë“¤ (í˜¸í…” ì„œë¹„ìŠ¤ë¡œ ê°„ì£¼)\n",
        "]\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment'] # 'more'ëŠ” service_keywordsë¡œ ì´ë™\n",
        "\n",
        "# ê²½í—˜/ìƒí™© ê´€ë ¨ í‚¤ì›Œë“œ : ì¡°ì¥ë‹˜ í”¼ë“œë°± ë°˜ì˜\n",
        "# 'thing', 'day', 'side', 'people', 'option', 'place', 'hand', 'minute', 'hour' ë“±ì€  'other'ë¡œ ë¹ ì§€ë„ë¡ ë†”ë‘ \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MlctZ_sXK2Ex"
      },
      "id": "MlctZ_sXK2Ex"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q: other ì²˜ë¦¬ ì¶”ê°€ë²„ì „"
      ],
      "metadata": {
        "id": "Vd6T5aKpLuoW"
      },
      "id": "Vd6T5aKpLuoW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- negative_reviews_analysis_1 íŒŒì¼ ì´ìš©\n",
        "- other ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ê¶Œì— ìˆëŠ”, ë˜ëŠ” ì˜ë¯¸ê°€ ëª…í™•í•œ ë‹¨ì–´ë“¤ì„ ë½‘ì•„ì„œ ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€"
      ],
      "metadata": {
        "id": "48QjRb1pL_WV"
      },
      "id": "48QjRb1pL_WV"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_pairs = pd.read_csv(\"/content/noun_adj_pairs_raw(neg).csv\")\n",
        "\n",
        "\n",
        "# ì¹´í…Œê³ ë¦¬ ë¼ë²¨ë§ í•¨ìˆ˜ ì •ì˜\n",
        "def assign_category_by_noun_priority(adj, noun):\n",
        "    categories = []\n",
        "    adj_lower = str(adj).lower() if pd.notna(adj) else ''\n",
        "    noun_lower = str(noun).lower() if pd.notna(noun) else ''\n",
        "\n",
        "    # 1ìˆœìœ„: ëª…ì‚¬(noun)ê°€ ì–´ë–¤ í‚¤ì›Œë“œì— ì†í•˜ëŠ”ì§€ í™•ì¸\n",
        "    for category, keywords in processed_keyword_categories.items():\n",
        "        if any(kw in noun_lower for kw in keywords):\n",
        "            if category not in categories:\n",
        "                categories.append(category)\n",
        "\n",
        "    # 2ìˆœìœ„: í˜•ìš©ì‚¬(adj)ê°€ ëª…í™•í•œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œì¼ ë•Œ (and ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ì— í•œí•´)\n",
        "    for category, keywords in processed_keyword_categories.items():\n",
        "        if any(kw in adj_lower for kw in keywords):\n",
        "            if category not in categories:\n",
        "                categories.append(category)\n",
        "\n",
        "    # ë§Œì•½ ì•„ë¬´ ì¹´í…Œê³ ë¦¬ë„ í• ë‹¹ë˜ì§€ ì•Šì•˜ë‹¤ë©´ 'other'\n",
        "    return categories if categories else ['other']\n",
        "\n",
        "\n",
        "# 5. ë°ì´í„°í”„ë ˆì„ì— ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¶”ê°€\n",
        "df_pairs['categories'] = df_pairs.apply(lambda row: assign_category_by_noun_priority(row['adj'], row['noun']), axis=1)\n",
        "\n",
        "# 6. ë¹ˆë„ìˆ˜ ê³„ì‚°\n",
        "pair_counts = Counter(tuple(row) for row in df_pairs[['adj', 'noun']].values)\n",
        "\n",
        "# 7. 'other' ì¹´í…Œê³ ë¦¬ ìƒìœ„ ìŒ í™•ì¸\n",
        "other_pairs_df = df_pairs[df_pairs['categories'].apply(lambda x: 'other' in x)].copy()\n",
        "\n",
        "if not other_pairs_df.empty:\n",
        "    other_pairs_df['count'] = other_pairs_df.apply(lambda row: pair_counts.get((row['adj'], row['noun']), 0), axis=1)\n",
        "    print(\"\\n### (ì°¸ê³ ) ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ 'other' ì¹´í…Œê³ ë¦¬ ìƒìœ„ ìŒ (ë¹ˆë„ìˆ˜ ê¸°ì¤€) ###\")\n",
        "    print(other_pairs_df.sort_values(by='count', ascending=False).head(10).to_string())\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "\n",
        "    distinct_other_pairs = other_pairs_df[['adj', 'noun']].drop_duplicates()\n",
        "    print(\"\\n### ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ 'other' ì¹´í…Œê³ ë¦¬ì˜ ê³ ìœ í•œ ìŒë“¤ (Distinct Pairs) ###\")\n",
        "    if len(distinct_other_pairs) > 10:\n",
        "        print(f\"ì´ {len(distinct_other_pairs)}ê°œì˜ ê³ ìœ í•œ ìŒ ì¤‘ ìƒìœ„ 10ê°œ:\")\n",
        "        print(distinct_other_pairs.head(10).to_string(index=False))\n",
        "    else:\n",
        "        print(f\"ì´ {len(distinct_other_pairs)}ê°œì˜ ê³ ìœ í•œ ìŒ:\")\n",
        "        print(distinct_other_pairs.to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"\\nâ— 'other' ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë‹¨ì–´ ìŒì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"ğŸ‰ ìµœì¢… ë¼ë²¨ë§ ê²°ê³¼ (ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¶”ê°€ëœ ë²„ì „) ğŸ‰\")\n",
        "print(df_pairs.head(10).to_string())\n",
        "\n",
        "print(\"\\nğŸ“ˆ ê° ì¹´í…Œê³ ë¦¬ë³„ ìŒì˜ ê°œìˆ˜ ğŸ“ˆ\")\n",
        "all_assigned_categories = [cat for sublist in df_pairs['categories'] for cat in sublist]\n",
        "print(Counter(all_assigned_categories))"
      ],
      "metadata": {
        "id": "zV6ITD4zACKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f3d859-f33f-4c85-e62d-dd650b26b2c8"
      },
      "id": "zV6ITD4zACKc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### (ì°¸ê³ ) ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ 'other' ì¹´í…Œê³ ë¦¬ ìƒìœ„ ìŒ (ë¹ˆë„ìˆ˜ ê¸°ì¤€) ###\n",
            "          adj  noun categories  count\n",
            "100491  front  desk    [other]   1451\n",
            "100348  front  desk    [other]   1451\n",
            "207336  front  desk    [other]   1451\n",
            "168335  front  desk    [other]   1451\n",
            "207008  front  desk    [other]   1451\n",
            "6156    front  desk    [other]   1451\n",
            "6165    front  desk    [other]   1451\n",
            "100124  front  desk    [other]   1451\n",
            "100160  front  desk    [other]   1451\n",
            "70      front  desk    [other]   1451\n",
            "----------------------------------------------------------------\n",
            "\n",
            "### ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ 'other' ì¹´í…Œê³ ë¦¬ì˜ ê³ ìœ í•œ ìŒë“¤ (Distinct Pairs) ###\n",
            "ì´ 47563ê°œì˜ ê³ ìœ í•œ ìŒ ì¤‘ ìƒìœ„ 10ê°œ:\n",
            "      adj      noun\n",
            " possible      site\n",
            "      bio    weapon\n",
            "     next       day\n",
            "     good       way\n",
            "wonderful     waist\n",
            " peaceful    garden\n",
            " internal    garden\n",
            "    audio recording\n",
            "   single     level\n",
            "    basic    coffee\n",
            "\n",
            "---\n",
            "ğŸ‰ ìµœì¢… ë¼ë²¨ë§ ê²°ê³¼ (ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¶”ê°€ëœ ë²„ì „) ğŸ‰\n",
            "        adj     noun                             categories\n",
            "0  possible     site                                [other]\n",
            "1     small     room  [service, facility_amenity, roomsize]\n",
            "2       big   window                     [facility_amenity]\n",
            "3      high  ceiling                            [expensive]\n",
            "4      mini   fridge                     [facility_amenity]\n",
            "5       bio   weapon                                [other]\n",
            "6      more   volume                              [service]\n",
            "7      high  ceiling                            [expensive]\n",
            "8      next      day                                [other]\n",
            "9      next      day                                [other]\n",
            "\n",
            "ğŸ“ˆ ê° ì¹´í…Œê³ ë¦¬ë³„ ìŒì˜ ê°œìˆ˜ ğŸ“ˆ\n",
            "Counter({'other': 133385, 'service': 84101, 'facility_amenity': 75724, 'roomsize': 21607, 'dirty': 14581, 'expensive': 7586, 'transport': 7049, 'noisy': 6473, 'eat': 3588, 'attraction': 3153})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------"
      ],
      "metadata": {
        "id": "yNbIILdfQ-y4"
      },
      "id": "yNbIILdfQ-y4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ìµœì¢… ë²„ì „"
      ],
      "metadata": {
        "id": "JyZcy72pSgXL"
      },
      "id": "JyZcy72pSgXL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[ìµœì¢… ë²„ì „] : í”¼ë“œë°± ë°˜ì˜ + other ì„¸ë¶€ ë‹¨ì–´ ì¶”ê°€\n",
        "\n",
        "facility_amenity_keywords = [\n",
        "    'hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress',\n",
        "    'wifi', 'connection', 'elevator', 'lift', 'fridge', 'lighting', 'tub', 'shower',\n",
        "    'air',\n",
        "    'level','audio','recording'\n",
        "]\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds','sleep']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell', 'bad']\n",
        "service_keywords = [\n",
        "    'lovely', 'friendly', 'staff', 'helpful', 'polite', 'reception', 'service',\n",
        "    'balcony', 'room', 'breakfast', 'tidy',\n",
        "    'poor', 'slow', 'old', 'cold', 'more', #\n",
        "    'value', 'quality', 'check', 'experience', 'response',\n",
        "    'food', 'drink', 'egg', 'selection',\n",
        "    'desk', 'day','coffee'\n",
        "]\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "attraction_keywords = ['museum', 'park', 'view' 'beautiful', 'amazing',\n",
        "'garden'\n",
        "]\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']\n",
        "\n",
        "ê²½í—˜/ìƒí™© ê´€ë ¨ í‚¤ì›Œë“œ : ì¡°ì¥ë‹˜ í”¼ë“œë°± ë°˜ì˜\n",
        "'thing', 'way', 'side', 'people', 'option', 'place', 'hand', 'minute', 'hour' ë“±ì€  'other'ë¡œ ë¹ ì§€ë„ë¡ ë†”ë‘ "
      ],
      "metadata": {
        "id": "7PeA4FlXRAr0"
      },
      "id": "7PeA4FlXRAr0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}