{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------"
      ],
      "metadata": {
        "id": "37NcAZgkOQ4n"
      },
      "id": "37NcAZgkOQ4n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 라벨링 시이작"
      ],
      "metadata": {
        "id": "yayrd0yZ7EDr"
      },
      "id": "yayrd0yZ7EDr"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as numpy"
      ],
      "metadata": {
        "id": "HEZo5JAPORkY"
      },
      "id": "HEZo5JAPORkY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attraction: museum, park,view,beautiful,amazing\n",
        "#eat:restaurant, bar\n",
        "#transport: great,train, subway,metro, bus,station,metre,underground, transport, access, location, centre, position,tube\n",
        "#service: lovely, friendly, staff, helpful,balcony, room, breakfast, tidy, polite, reception"
      ],
      "metadata": {
        "id": "CGCUvXrmOToY"
      },
      "id": "CGCUvXrmOToY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception']\n",
        "\n",
        "roomsize_keywords = ['tidy, narrows, narrow, compact, small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']"
      ],
      "metadata": {
        "id": "kyzX1qkTOVhI"
      },
      "id": "kyzX1qkTOVhI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------"
      ],
      "metadata": {
        "id": "CzEeY2OvogK3"
      },
      "id": "CzEeY2OvogK3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# noun_adj_pairs_raw(neg) 파일 먼저 이용!"
      ],
      "metadata": {
        "id": "zWBnKfUlomto"
      },
      "id": "zWBnKfUlomto"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "df = pd.read_csv('/content/noun_adj_pairs_raw(neg).csv')\n",
        "\n",
        "print(\"원본 데이터\")\n",
        "print(df)\n",
        "print(\"---\")\n",
        "\n",
        "# 정원님이 만든 키워드 딕셔너리\n",
        "keywords_dict = {\n",
        "    'attraction': ['museum', 'park', 'view', 'beautiful', 'amazing'],\n",
        "    'eat': ['restaurant', 'bar'],\n",
        "    'transport': ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube'],\n",
        "    'service': ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception'],\n",
        "    'roomsize': ['tiny', 'narrows', 'narrow', 'compact', 'small'],\n",
        "    'noisy': ['noise', 'noisy', 'soundproofng', 'soundproof', 'sound', 'sounds'],\n",
        "    'dirty': ['dirty', 'uncleaned', 'cleaned', 'toilet', 'bathroom', 'pillow', 'bug', 'smell'],\n",
        "    'expensive': ['expensive', 'price', 'pricy', 'high', 'prices', 'payment']\n",
        "}\n",
        "\n",
        "# 라벨링 함수를 만들어보자!\n",
        "def assign_label(text):\n",
        "    if pd.isna(text): # 혹시 텍스트가 비어있는 경우 (NaN)를 대비\n",
        "        return 'Not Applicable'\n",
        "    text = str(text).lower() # 대소문자 상관없이 찾으려면 소문자로 다 바꿔주기. 및 문자열!\n",
        "\n",
        "    for label, keywords in keywords_dict.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                    return label # 키워드를 찾으면 해당 라벨을 반환하고 끝!\n",
        "    return 'Other/General' # 키워드를 하나도 못 찾으면 'Other/General'키워드\n",
        "\n",
        "\n",
        "# 형용사와 명사를 띄어쓰기로 연결해서 하나의 문장처럼 만들기\n",
        "df['combined_text'] = df['adj'].astype(str) + ' ' + df['noun'].astype(str)\n",
        "\n",
        "# 새로운 'label' 컬럼을 추가해서 함수를 적용\n",
        "df['label'] = df['combined_text'].apply(assign_label)\n",
        "\n",
        "print(df[['adj', 'noun', 'combined_text', 'label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnLofHglOXzI",
        "outputId": "a95b551d-b8bb-4a72-c680-9cd93bbcb459"
      },
      "id": "NnLofHglOXzI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 데이터\n",
            "             adj     noun\n",
            "0       possible     site\n",
            "1          small     room\n",
            "2            big   window\n",
            "3           high  ceiling\n",
            "4           mini   fridge\n",
            "...          ...      ...\n",
            "285664      free  parking\n",
            "285665    public   garage\n",
            "285666       hot     week\n",
            "285667      more      air\n",
            "285668       hot      air\n",
            "\n",
            "[285669 rows x 2 columns]\n",
            "---\n",
            "             adj     noun  combined_text          label\n",
            "0       possible     site  possible site  Other/General\n",
            "1          small     room     small room        service\n",
            "2            big   window     big window  Other/General\n",
            "3           high  ceiling   high ceiling      expensive\n",
            "4           mini   fridge    mini fridge  Other/General\n",
            "...          ...      ...            ...            ...\n",
            "285664      free  parking   free parking     attraction\n",
            "285665    public   garage  public garage  Other/General\n",
            "285666       hot     week       hot week  Other/General\n",
            "285667      more      air       more air  Other/General\n",
            "285668       hot      air        hot air  Other/General\n",
            "\n",
            "[285669 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bert 파일 이용"
      ],
      "metadata": {
        "id": "thWZ0wPkszgV"
      },
      "id": "thWZ0wPkszgV"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# 1. 수동으로 정의한 키워드 리스트\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception']\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']\n",
        "\n",
        "# 모든 수동 키워드를 하나의 세트로 통합\n",
        "manual_keywords = set(attraction_keywords + eat_keywords + transport_keywords + service_keywords + roomsize_keywords + noisy_keywords + dirty_keywords + expensive_keywords)\n",
        "\n",
        "# 2. BERT 부정 리뷰 분석 파일 로드\n",
        "df_bert_neg  = pd.read_csv(\"/content/negative_reviews_analysis_1.csv\")\n",
        "\n",
        "# 3. BERT 파일에서 모든 단어 추출\n",
        "all_words = []\n",
        "for pair_string in df_bert_neg['word_pair']:\n",
        "    try:\n",
        "        pair = eval(pair_string)\n",
        "        if isinstance(pair, tuple) and len(pair) == 2:\n",
        "            all_words.extend(pair)\n",
        "    except (SyntaxError, NameError):\n",
        "        continue\n",
        "\n",
        "# 4. 수동 키워드 리스트에 없는 단어(새로운 키워드 후보) 찾기\n",
        "new_keywords_candidates = [word for word in all_words if word not in manual_keywords]\n",
        "\n",
        "# 5. 새로운 키워드 후보의 빈도수 계산 및 상위 20개 출력\n",
        "new_keyword_counts = Counter(new_keywords_candidates)\n",
        "\n",
        "print(\"\\n--- BERT 분석에서 발견된 새로운 키워드 후보 (상위 20개) ---\")\n",
        "for word, count in new_keyword_counts.most_common(20):\n",
        "    print(f\"  - {word}: {count:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "7rZ5s0p_r1Qc",
        "outputId": "8d4490df-7c26-49ed-c755-0afea80b3aa4"
      },
      "id": "7rZ5s0p_r1Qc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/negative_reviews_analysis_1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3112654589.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 2. BERT 부정 리뷰 분석 파일 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_bert_neg\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/negative_reviews_analysis_1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 3. BERT 파일에서 모든 단어 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/negative_reviews_analysis_1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_pair컬럼 사용해서, 빈도수 찾아내기!"
      ],
      "metadata": {
        "id": "nmaRWJEv3nbL"
      },
      "id": "nmaRWJEv3nbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "import string\n",
        "\n",
        "# 분석 대상 형용사 정의\n",
        "# 명사에 대한 꾸밈에 집중할 만한 형용사들\n",
        "# 'bed', 'hotel', 'service' 등은 명사에 더 가까워서 이 리스트에서 제외\n",
        "target_adjectives = ['very', 'too', 'poor', 'good', 'bad', 'hot', 'old', 'cold', 'slow', 'other', 'more', 'much']\n",
        "\n",
        "# 'word_pair' 컬럼에서 형용사와 명사 분리\n",
        "def parse_word_pair(pair_string):\n",
        "    try:\n",
        "        if pair_string.startswith('(') and pair_string.endswith(')'): #'string' 리터럴이 아닌 실제 파이썬 튜플 형태인지 확인\n",
        "            pair = eval(pair_string)\n",
        "            if isinstance(pair, tuple) and len(pair) == 2:\n",
        "                adj = str(pair[0]).strip() # 튜플 요소의 타입도 확인하여 불필요한 공백 제거\n",
        "                noun = str(pair[1]).strip()\n",
        "                return (adj, noun)\n",
        "        return None\n",
        "    except (SyntaxError, NameError, TypeError): # TypeError도 추가해서 좀 더 견고하게!\n",
        "        return None\n",
        "\n",
        "df_bert_neg['word_pair_tuple'] = df_bert_neg['word_pair'].apply(parse_word_pair)\n",
        "df_bert_neg.dropna(subset=['word_pair_tuple'], inplace=True) # 유효하지 않은 쌍 제거\n",
        "\n",
        "# 해당 타겟 형용사가 포함된 쌍만 필터링\n",
        "for target_adj in target_adjectives:\n",
        "    filtered_pairs = df_bert_neg[df_bert_neg['word_pair_tuple'].apply(lambda x: x[0] == target_adj)] # word_pair_tuple은 (adj, noun) 형태의 튜플이므로, adj가 target_adj와 같은지 확인\n",
        "\n",
        "    # 해당 형용사가 꾸며주는 명사들만 추출\n",
        "    nouns_for_adj = [pair[1] for pair in filtered_pairs['word_pair_tuple']]\n",
        "\n",
        "    if nouns_for_adj: # 명사가 하나라도 있으면 출력\n",
        "        noun_counts_for_adj = Counter(nouns_for_adj).most_common(10)\n",
        "        print(f\"'{target_adj}'이(가) 꾸며주는 명사 (총 {len(nouns_for_adj):,}개) :\")\n",
        "        for noun, count in noun_counts_for_adj:\n",
        "            print(f\"  - {noun}: {count:,}\")\n",
        "        print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kxCKd7etgpI",
        "outputId": "2eaebf16-0856-49f3-8d19-7cc13ed06e1c"
      },
      "id": "4kxCKd7etgpI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'very'이(가) 꾸며주는 명사 (총 10,698개) :\n",
            "  - small: 1,298\n",
            "  - poor: 718\n",
            "  - noisy: 571\n",
            "  - expensive: 537\n",
            "  - slow: 348\n",
            "  - bad: 332\n",
            "  - good: 272\n",
            "  - hot: 266\n",
            "  - uncomfortable: 231\n",
            "  - old: 224\n",
            "--------------------------------------------------\n",
            "'too'이(가) 꾸며주는 명사 (총 3,664개) :\n",
            "  - small: 819\n",
            "  - expensive: 386\n",
            "  - hot: 302\n",
            "  - much: 224\n",
            "  - soft: 138\n",
            "  - high: 131\n",
            "  - warm: 96\n",
            "  - noisy: 96\n",
            "  - many: 91\n",
            "  - hard: 88\n",
            "--------------------------------------------------\n",
            "'poor'이(가) 꾸며주는 명사 (총 1,678개) :\n",
            "  - service: 150\n",
            "  - breakfast: 114\n",
            "  - quality: 93\n",
            "  - value: 69\n",
            "  - room: 60\n",
            "  - wifi: 54\n",
            "  - staff: 47\n",
            "  - selection: 35\n",
            "  - lighting: 35\n",
            "  - connection: 32\n",
            "--------------------------------------------------\n",
            "'good'이(가) 꾸며주는 명사 (총 1,160개) :\n",
            "  - value: 96\n",
            "  - hotel: 44\n",
            "  - sleep: 43\n",
            "  - service: 36\n",
            "  - room: 36\n",
            "  - thing: 29\n",
            "  - location: 27\n",
            "  - breakfast: 26\n",
            "  - experience: 26\n",
            "  - idea: 23\n",
            "--------------------------------------------------\n",
            "'bad'이(가) 꾸며주는 명사 (총 1,207개) :\n",
            "  - experience: 141\n",
            "  - smell: 110\n",
            "  - room: 57\n",
            "  - thing: 48\n",
            "  - hotel: 42\n",
            "  - service: 41\n",
            "  - sleep: 28\n",
            "  - wifi: 27\n",
            "  - breakfast: 25\n",
            "  - staff: 24\n",
            "--------------------------------------------------\n",
            "'hot'이(가) 꾸며주는 명사 (총 815개) :\n",
            "  - water: 238\n",
            "  - food: 54\n",
            "  - breakfast: 34\n",
            "  - room: 33\n",
            "  - day: 25\n",
            "  - drink: 23\n",
            "  - air: 23\n",
            "  - t: 20\n",
            "  - tub: 13\n",
            "  - shower: 12\n",
            "--------------------------------------------------\n",
            "'old'이(가) 꾸며주는 명사 (총 851개) :\n",
            "  - room: 60\n",
            "  - hotel: 51\n",
            "  - furniture: 48\n",
            "  - building: 34\n",
            "  - carpet: 26\n",
            "  - bathroom: 24\n",
            "  - bed: 22\n",
            "  - window: 20\n",
            "  - facility: 17\n",
            "  - mattress: 13\n",
            "--------------------------------------------------\n",
            "'cold'이(가) 꾸며주는 명사 (총 474개) :\n",
            "  - water: 50\n",
            "  - room: 35\n",
            "  - air: 33\n",
            "  - shower: 26\n",
            "  - breakfast: 17\n",
            "  - food: 17\n",
            "  - t: 12\n",
            "  - egg: 11\n",
            "  - drink: 10\n",
            "  - bathroom: 9\n",
            "--------------------------------------------------\n",
            "'slow'이(가) 꾸며주는 명사 (총 329개) :\n",
            "  - service: 63\n",
            "  - wifi: 33\n",
            "  - check: 26\n",
            "  - elevator: 21\n",
            "  - staff: 12\n",
            "  - room: 10\n",
            "  - connection: 10\n",
            "  - internet: 10\n",
            "  - lift: 8\n",
            "  - response: 5\n",
            "--------------------------------------------------\n",
            "'other'이(가) 꾸며주는 명사 (총 1,323개) :\n",
            "  - hotel: 220\n",
            "  - room: 186\n",
            "  - guest: 112\n",
            "  - side: 47\n",
            "  - people: 40\n",
            "  - thing: 31\n",
            "  - staff: 30\n",
            "  - option: 22\n",
            "  - place: 20\n",
            "  - hand: 14\n",
            "--------------------------------------------------\n",
            "'more'이(가) 꾸며주는 명사 (총 1,169개) :\n",
            "  - expensive: 47\n",
            "  - comfortable: 34\n",
            "  - space: 28\n",
            "  - staff: 24\n",
            "  - money: 22\n",
            "  - room: 20\n",
            "  - helpful: 19\n",
            "  - minute: 17\n",
            "  - hour: 17\n",
            "  - friendly: 16\n",
            "--------------------------------------------------\n",
            "'much'이(가) 꾸며주는 명사 (총 774개) :\n",
            "  - well: 141\n",
            "  - noise: 54\n",
            "  - small: 53\n",
            "  - more: 33\n",
            "  - time: 25\n",
            "  - room: 25\n",
            "  - money: 19\n",
            "  - space: 17\n",
            "  - choice: 14\n",
            "  - sleep: 14\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "갯수가 좀 적더라도 명사에 집중!\n",
        "\n",
        "\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "service_keywords = ['lovely', 'friendly', 'staff', 'helpful', 'balcony', 'room', 'breakfast', 'tidy', 'polite', 'reception', 'poor','slow','other','old','cold']\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell','bad']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment','more']\n",
        "\n",
        "\n",
        "\n",
        "- very 형용사를 꾸며주는 역할이 너무 강해서 제외\n",
        "- too 형용사를 꾸며주는 역할이 너무 강해서 제외\n",
        "- poor -> service/breakfast/quality -> service\n",
        "- good -> value/hotel/sleep -> ?\n",
        "- bad -> experience/smell/room -> dirty\n",
        "- hot -> water/food/breakfast -> ?\n",
        "- old -> room/hotel/furniture -> service\n",
        "- cold -> water/room/air -> service\n",
        "- slow -> service/wifi/check -> service\n",
        "- other -> hotel/room/guest -> service\n",
        "- more -> expensive/comfortable/space -> expensive\n",
        "- much 형용사를 꾸며주는 역할이 너무 강해서 제외"
      ],
      "metadata": {
        "id": "rzwQsVGn6ggE"
      },
      "id": "rzwQsVGn6ggE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "추가적인 의견,,,!\n",
        "\n",
        "# \"시설/어메니티\" 관련 명사들을 위한 카테고리 강화\n",
        "facility_amenity_keywords = ['hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress', 'wifi', 'connection', 'elevator', 'lift', 'fridge', 'quality', 'value', 'lighting', 'tub', 'shower']\n",
        "\n",
        "# \"경험/상황\" 관련 명사 카테고리 (추상적인 것 포함)\n",
        "experience_condition_keywords = ['experience', 'sleep', 'thing', 'day', 'smell', 'response', 'time', 'space']\n",
        "\n",
        "# \"식사/음식\" 관련 명사 카테고리\n",
        "food_keywords = ['breakfast', 'food', 'drink', 'egg', 'selection']\n",
        "\n",
        "이런식으로 더 나누는거보다는 이대로 유지하는게 낫게쬬,,?!??!\n"
      ],
      "metadata": {
        "id": "A_nlMed_-Tmt"
      },
      "id": "A_nlMed_-Tmt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피드백 반영"
      ],
      "metadata": {
        "id": "ZEEYmdvVH_bY"
      },
      "id": "ZEEYmdvVH_bY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "facility_amenity_keywords = [\n",
        "    'hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress',\n",
        "    'wifi', 'connection', 'elevator', 'lift', 'fridge', 'lighting', 'tub', 'shower',\n",
        "    'air' # 'hot', 'cold'가 꾸미던 'air' 추가\n",
        "]\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small'] # 'room'은 service_keywords로 이동\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds','sleep'] # 'sleep'추가\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell', 'bad'] # 'bad'를 청결도와 연관\n",
        "service_keywords = [\n",
        "    'lovely', 'friendly', 'staff', 'helpful', 'polite', 'reception', 'service', # 기본적인 서비스 요소\n",
        "    'balcony', 'room', 'breakfast', 'tidy', # 'room', 'balcony'는 시설적 서비스, 'breakfast', 'tidy'는 서비스 품질 관련\n",
        "    'poor', 'slow', 'old', 'cold', 'more', # BERT에서 나온 형용사/부사들을 서비스 및 환경 상태 평가 요소로 포함\n",
        "    'value', 'quality', 'check', 'experience', 'response', # poor, good이 꾸미던 추상적인 명사 중 서비스와 연관\n",
        "    'food', 'drink', 'egg', 'selection' # 식사/음식 관련 명사들 (호텔 서비스로 간주)\n",
        "]\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "attraction_keywords = ['museum', 'park', 'view', 'beautiful', 'amazing']\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment'] # 'more'는 service_keywords로 이동\n",
        "\n",
        "# 경험/상황 관련 키워드 : 조장님 피드백 반영\n",
        "# 'thing', 'day', 'side', 'people', 'option', 'place', 'hand', 'minute', 'hour' 등은  'other'로 빠지도록 놔둠\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MlctZ_sXK2Ex"
      },
      "id": "MlctZ_sXK2Ex"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q: other 처리 추가버전"
      ],
      "metadata": {
        "id": "Vd6T5aKpLuoW"
      },
      "id": "Vd6T5aKpLuoW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- negative_reviews_analysis_1 파일 이용\n",
        "- other 카테고리에서 상위권에 있는, 또는 의미가 명확한 단어들을 뽑아서 기존 카테고리에 추가"
      ],
      "metadata": {
        "id": "48QjRb1pL_WV"
      },
      "id": "48QjRb1pL_WV"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_pairs = pd.read_csv(\"/content/noun_adj_pairs_raw(neg).csv\")\n",
        "\n",
        "\n",
        "# 카테고리 라벨링 함수 정의\n",
        "def assign_category_by_noun_priority(adj, noun):\n",
        "    categories = []\n",
        "    adj_lower = str(adj).lower() if pd.notna(adj) else ''\n",
        "    noun_lower = str(noun).lower() if pd.notna(noun) else ''\n",
        "\n",
        "    # 1순위: 명사(noun)가 어떤 키워드에 속하는지 확인\n",
        "    for category, keywords in processed_keyword_categories.items():\n",
        "        if any(kw in noun_lower for kw in keywords):\n",
        "            if category not in categories:\n",
        "                categories.append(category)\n",
        "\n",
        "    # 2순위: 형용사(adj)가 명확한 카테고리 키워드일 때 (and 아직 추가되지 않은 카테고리에 한해)\n",
        "    for category, keywords in processed_keyword_categories.items():\n",
        "        if any(kw in adj_lower for kw in keywords):\n",
        "            if category not in categories:\n",
        "                categories.append(category)\n",
        "\n",
        "    # 만약 아무 카테고리도 할당되지 않았다면 'other'\n",
        "    return categories if categories else ['other']\n",
        "\n",
        "\n",
        "# 5. 데이터프레임에 카테고리 컬럼 추가\n",
        "df_pairs['categories'] = df_pairs.apply(lambda row: assign_category_by_noun_priority(row['adj'], row['noun']), axis=1)\n",
        "\n",
        "# 6. 빈도수 계산\n",
        "pair_counts = Counter(tuple(row) for row in df_pairs[['adj', 'noun']].values)\n",
        "\n",
        "# 7. 'other' 카테고리 상위 쌍 확인\n",
        "other_pairs_df = df_pairs[df_pairs['categories'].apply(lambda x: 'other' in x)].copy()\n",
        "\n",
        "if not other_pairs_df.empty:\n",
        "    other_pairs_df['count'] = other_pairs_df.apply(lambda row: pair_counts.get((row['adj'], row['noun']), 0), axis=1)\n",
        "    print(\"\\n### (참고) 라벨링 되지 않은 'other' 카테고리 상위 쌍 (빈도수 기준) ###\")\n",
        "    print(other_pairs_df.sort_values(by='count', ascending=False).head(10).to_string())\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "\n",
        "    distinct_other_pairs = other_pairs_df[['adj', 'noun']].drop_duplicates()\n",
        "    print(\"\\n### 라벨링 되지 않은 'other' 카테고리의 고유한 쌍들 (Distinct Pairs) ###\")\n",
        "    if len(distinct_other_pairs) > 10:\n",
        "        print(f\"총 {len(distinct_other_pairs)}개의 고유한 쌍 중 상위 10개:\")\n",
        "        print(distinct_other_pairs.head(10).to_string(index=False))\n",
        "    else:\n",
        "        print(f\"총 {len(distinct_other_pairs)}개의 고유한 쌍:\")\n",
        "        print(distinct_other_pairs.to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"\\n❗ 'other' 카테고리에 속하는 단어 쌍이 없습니다.\")\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"🎉 최종 라벨링 결과 (카테고리 컬럼 추가된 버전) 🎉\")\n",
        "print(df_pairs.head(10).to_string())\n",
        "\n",
        "print(\"\\n📈 각 카테고리별 쌍의 개수 📈\")\n",
        "all_assigned_categories = [cat for sublist in df_pairs['categories'] for cat in sublist]\n",
        "print(Counter(all_assigned_categories))"
      ],
      "metadata": {
        "id": "zV6ITD4zACKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f3d859-f33f-4c85-e62d-dd650b26b2c8"
      },
      "id": "zV6ITD4zACKc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### (참고) 라벨링 되지 않은 'other' 카테고리 상위 쌍 (빈도수 기준) ###\n",
            "          adj  noun categories  count\n",
            "100491  front  desk    [other]   1451\n",
            "100348  front  desk    [other]   1451\n",
            "207336  front  desk    [other]   1451\n",
            "168335  front  desk    [other]   1451\n",
            "207008  front  desk    [other]   1451\n",
            "6156    front  desk    [other]   1451\n",
            "6165    front  desk    [other]   1451\n",
            "100124  front  desk    [other]   1451\n",
            "100160  front  desk    [other]   1451\n",
            "70      front  desk    [other]   1451\n",
            "----------------------------------------------------------------\n",
            "\n",
            "### 라벨링 되지 않은 'other' 카테고리의 고유한 쌍들 (Distinct Pairs) ###\n",
            "총 47563개의 고유한 쌍 중 상위 10개:\n",
            "      adj      noun\n",
            " possible      site\n",
            "      bio    weapon\n",
            "     next       day\n",
            "     good       way\n",
            "wonderful     waist\n",
            " peaceful    garden\n",
            " internal    garden\n",
            "    audio recording\n",
            "   single     level\n",
            "    basic    coffee\n",
            "\n",
            "---\n",
            "🎉 최종 라벨링 결과 (카테고리 컬럼 추가된 버전) 🎉\n",
            "        adj     noun                             categories\n",
            "0  possible     site                                [other]\n",
            "1     small     room  [service, facility_amenity, roomsize]\n",
            "2       big   window                     [facility_amenity]\n",
            "3      high  ceiling                            [expensive]\n",
            "4      mini   fridge                     [facility_amenity]\n",
            "5       bio   weapon                                [other]\n",
            "6      more   volume                              [service]\n",
            "7      high  ceiling                            [expensive]\n",
            "8      next      day                                [other]\n",
            "9      next      day                                [other]\n",
            "\n",
            "📈 각 카테고리별 쌍의 개수 📈\n",
            "Counter({'other': 133385, 'service': 84101, 'facility_amenity': 75724, 'roomsize': 21607, 'dirty': 14581, 'expensive': 7586, 'transport': 7049, 'noisy': 6473, 'eat': 3588, 'attraction': 3153})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------"
      ],
      "metadata": {
        "id": "yNbIILdfQ-y4"
      },
      "id": "yNbIILdfQ-y4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 버전"
      ],
      "metadata": {
        "id": "JyZcy72pSgXL"
      },
      "id": "JyZcy72pSgXL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[최종 버전] : 피드백 반영 + other 세부 단어 추가\n",
        "\n",
        "facility_amenity_keywords = [\n",
        "    'hotel', 'room', 'bed', 'water', 'furniture', 'building', 'carpet', 'window', 'mattress',\n",
        "    'wifi', 'connection', 'elevator', 'lift', 'fridge', 'lighting', 'tub', 'shower',\n",
        "    'air',\n",
        "    'level','audio','recording'\n",
        "]\n",
        "roomsize_keywords = ['tiny', 'narrows', 'narrow', 'compact', 'small']\n",
        "noisy_keywords = ['noise','noisy','soundproofng','soundproof','sound','sounds','sleep']\n",
        "dirty_keywords = ['dirty', 'uncleaned','cleaned', 'toilet', 'bathroom','pillow','bug','smell', 'bad']\n",
        "service_keywords = [\n",
        "    'lovely', 'friendly', 'staff', 'helpful', 'polite', 'reception', 'service',\n",
        "    'balcony', 'room', 'breakfast', 'tidy',\n",
        "    'poor', 'slow', 'old', 'cold', 'more', #\n",
        "    'value', 'quality', 'check', 'experience', 'response',\n",
        "    'food', 'drink', 'egg', 'selection',\n",
        "    'desk', 'day','coffee'\n",
        "]\n",
        "eat_keywords = ['restaurant', 'bar']\n",
        "transport_keywords = ['great', 'train', 'subway', 'metro', 'bus', 'station', 'metre', 'underground', 'transport', 'access', 'location', 'centre', 'position', 'tube']\n",
        "attraction_keywords = ['museum', 'park', 'view' 'beautiful', 'amazing',\n",
        "'garden'\n",
        "]\n",
        "expensive_keywords = ['expensive','price','pricy','high','prices','payment']\n",
        "\n",
        "경험/상황 관련 키워드 : 조장님 피드백 반영\n",
        "'thing', 'way', 'side', 'people', 'option', 'place', 'hand', 'minute', 'hour' 등은  'other'로 빠지도록 놔둠"
      ],
      "metadata": {
        "id": "7PeA4FlXRAr0"
      },
      "id": "7PeA4FlXRAr0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}